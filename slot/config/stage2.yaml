name: stage2_libero90_clip
stage: 2                            # 1 for train slot encoder, 2 for train dynamics, 3 for low-level policy

defaults:
- model: slot_predictor
- components/predictor: transformer
- components/decoder: rgb
- _self_

globals:
  slot_dim: 256
  text_dim: 512
  pretrained_encoder: data/outputs/2025_10_21/17_34_38_stage1/checkpoints/latest.ckpt               # encoder ckpt path
  freeze_mapping: True
  freeze_slot_attention: True
  freeze_decoder: False
  rgb_decoder: ${components.decoder}

dataset:
  _target_: slot.dataset.dataloader.get_libero_subgoal_image_dataloader
  dataset_path: data/libero/libero_90
  view: agentview_rgb
  seed: ${training.seed}
  train_batch_size: 32
  train_num_workers: 0
  train_pin_memory: True
  train_persistent_workers: False
  val_batch_size: 32
  val_num_workers: 0
  val_pin_memory: True
  val_persistent_workers: False

optimizer:
  _target_: torch.optim.AdamW
  _convert_: all
  lr: 3.0e-4
  betas: [0.95, 0.999]
  eps: 1.0e-8
  weight_decay: 1.0e-6

lr_scheduler: 
  name: cosine
  num_warmup_steps: 500

loss:
  sim_threshold: 3.5
  huber_delta: 1.0
  rgb_lp: 0.1                 # valid when training rgb reconstruction decoder
  rgb_entropy_alpha: 0.1      # valid when training rgb reconstruction decoder


checkpoint:
  topk:
    monitor_key: validation_loss
    mode: min
    k: 3
    format_str: 'epoch={epoch:04d}-validation_loss={validation_loss:.3f}.ckpt'
  save_last_ckpt: True

training:
  seed: 42
  device: cuda:0
  resume: False
  resume_ckpt: null
  debug: False
  num_epochs: 100
  max_train_steps: null
  max_val_steps: null
  val_every: 1
  checkpoint_every: 10
  tqdm_interval_sec: 1.0

logging:
  output_dir: data/outputs/${now:%Y_%m_%d}/${now:%H_%M_%S}_${name}
  wandb: True
  wandb_args:
    project: slot
    name: ${name}
    resume: True
    tags: ["${name}"]
    id: null
    group: null

hydra:
  job:
    override_dirname: ${name}
  run:
    dir: data/outputs/${now:%Y_%m_%d}/${now:%H_%M_%S}_${name}
  sweep:
    dir: data/outputs/${now:%Y_%m_%d}/${now:%H_%M_%S}_${name}
    subdir: ${hydra.job.num}